{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loss\n",
    "    We are considering the three types of losses during the training\n",
    "## Appearance Matching Loss:\n",
    "\n",
    "    If you give the left image as a inut to the network the network will generate 2 disparity maps,\n",
    "    one for the right and one for the left side. here we consider the disparity map created for the left side.\n",
    "    So if we have the right image and disparity map for the left image we can recreate the left image.\n",
    "    appearance matching loss considers the reconstructed left image and original left image and compair them.\n",
    "    we use L1 loss + simillarity loss combine to defne the appearance matching loss.\n",
    "    \n",
    "<img src=\"appearance.png\" title=\"Title text\" />\n",
    "    \n",
    "## Disparity Smoothness Loss:\n",
    "\n",
    "    So for the generated disparity maps there should not be abrupt changes in the disparity values. \n",
    "    And to ensure that we penalize the disparity map where we see the higher gradients.\n",
    "    \n",
    "<img src=\"disparity.png\" title=\"Title text\" />\n",
    "    \n",
    "## Left-Right Disparity Consistency Loss:\n",
    "\n",
    "    left image + disparity map for left = right image\n",
    "    right image + disparity map for right = left image\n",
    "    author assumes as the changes in the left and right images are minor both disparity maps should be almost equal\n",
    "    \n",
    "<img src=\"left-right.png\" title=\"Title text\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "def SSIM_loss(x, y):\n",
    "    \"\"\"Calculate Structural Similarity Score\n",
    "    Arguments:\n",
    "        x {tenosor} -- Image\n",
    "        y {tensor} -- Image\n",
    "    Returns:\n",
    "        floatTensor -- SSIM loss : (1- SSIM)/2 between 0 to 1\n",
    "    \"\"\"\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    mu_x = nn.functional.avg_pool2d(x, 3, 1, padding = 0)\n",
    "    mu_y = nn.functional.avg_pool2d(y, 3, 1, padding = 0)\n",
    "\n",
    "    sigma_x  = nn.functional.avg_pool2d(x ** 2, 3, 1, padding = 0) - mu_x ** 2\n",
    "    sigma_y  = nn.functional.avg_pool2d(y ** 2, 3, 1, padding = 0) - mu_y ** 2\n",
    "\n",
    "    sigma_xy = nn.functional.avg_pool2d(x * y , 3, 1, padding = 0) - mu_x * mu_y\n",
    "\n",
    "    SSIM_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    SSIM_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "\n",
    "    SSIM = SSIM_n / SSIM_d\n",
    "\n",
    "    return torch.clamp((1 - SSIM) / 2, 0, 1)\n",
    "\n",
    "def gradient_x(image):\n",
    "    \"\"\"Find gradient along x\n",
    "    Arguments:\n",
    "        image {tensor} -- image\n",
    "    Returns:\n",
    "        tensor -- dx(image)\n",
    "    \"\"\"\n",
    "    return image[:,:,:,:-1]-image[:,:,:,1:]\n",
    "\n",
    "def gradient_y(image):\n",
    "    \"\"\"Find gradient along y\n",
    "    Arguments:\n",
    "        image {tensor} -- image\n",
    "    Returns:\n",
    "        tensor -- dy(image)\n",
    "    \"\"\"\n",
    "    return image[:,:,:-1,:]-image[:,:,1:,:]\n",
    "\n",
    "def gradient_t(prev_image, image):\n",
    "    \"\"\"Find gradient along time: time derivative using two images\n",
    "    Arguments:\n",
    "        prev_image {tensor} -- image at timestamp 1\n",
    "        image {tensor} -- image at timestamp 2\n",
    "    Returns:\n",
    "        tensor -- time derivative of image\n",
    "    \"\"\"\n",
    "    return prev_image-image\n",
    "\n",
    "def disparity_smoothness(image, disparity):\n",
    "    \"\"\"Calculate \"Edge aware\" Disparity Smoothness loss \n",
    "    Arguments:\n",
    "        image {tensor} -- image\n",
    "        disparity {tensor} -- disparity\n",
    "    Returns:\n",
    "        FloatTensor -- loss \n",
    "    \"\"\"\n",
    "    grad_img_x = [gradient_x(i) for i in image]\n",
    "    grad_img_y = [gradient_y(i) for i in image]\n",
    "\n",
    "    grad_disp_x = [gradient_x(i) for i in disparity]\n",
    "    grad_disp_y = [gradient_y(i) for i in disparity]\n",
    "\n",
    "    weights_x = [torch.exp(-torch.mean(torch.abs(g), 1, keepdim=True)) for g in grad_img_x]\n",
    "    weights_y = [torch.exp(-torch.mean(torch.abs(g), 1, keepdim=True)) for g in grad_img_y]\n",
    "\n",
    "    smoothness_x = [grad_disp_x[i] * weights_x[i] for i in range(4)]\n",
    "    smoothness_y = [grad_disp_y[i] * weights_y[i] for i in range(4)]\n",
    "    \n",
    "    smoothness_x = [torch.nn.functional.pad(k,(0,1,0,0,0,0,0,0),mode='constant') for k in smoothness_x]\n",
    "    smoothness_y = [torch.nn.functional.pad(k,(0,0,0,1,0,0,0,0),mode='constant') for k in smoothness_y]\n",
    "\n",
    "    disp_smoothness = smoothness_x + smoothness_y\n",
    "\n",
    "    disp_loss = [torch.mean(torch.abs(disp_smoothness[i])) / 2 ** i for i in range(4)]\n",
    "    return disp_loss\n",
    "\n",
    "def LR_disparity_consistency(input_images, x_offset, wrap_mode='border', tensor_type = 'torch.FloatTensor'):\n",
    "    \"\"\"Implementation of Bilinear Sampling\n",
    "    Arguments:\n",
    "        input_images {tensor} -- Image\n",
    "        x_offset {tensor} -- tensor\n",
    "    Keyword Arguments:\n",
    "        wrap_mode {str} -- method of warp (default: {'border'})\n",
    "        tensor_type {str} -- datatype (default: {'torch.FloatTensor'})\n",
    "    Returns:\n",
    "        tensor -- image applied bilinear sampling\n",
    "    \"\"\"\n",
    "    is_gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if is_gpu_available:\n",
    "        tensor_type = 'torch.cuda.FloatTensor'\n",
    "    num_batch, num_channels, height, width = input_images.size()\n",
    "\n",
    "    # Handle both texture border types\n",
    "    edge_size = 0\n",
    "    if wrap_mode == 'border':\n",
    "        edge_size = 1\n",
    "        # Pad last and second-to-last dimensions by 1 from both sides\n",
    "        input_images = pad(input_images, (1, 1, 1, 1))\n",
    "    elif wrap_mode == 'edge':\n",
    "        edge_size = 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Put channels to slowest dimension and flatten batch with respect to others\n",
    "    input_images = input_images.permute(1, 0, 2, 3).contiguous()\n",
    "    im_flat = input_images.view(num_channels, -1)\n",
    "\n",
    "    # Create meshgrid for pixel indicies (PyTorch doesn't have dedicated meshgrid function)\n",
    "    x = torch.linspace(0, width - 1, width).repeat(height, 1).type(tensor_type).to(torch.device(\"cuda:0\"))\n",
    "    y = torch.linspace(0, height - 1, height).repeat(width, 1).transpose(0, 1).type(tensor_type).to(torch.device(\"cuda:0\"))\n",
    "    # Take padding into account\n",
    "    x = x + edge_size\n",
    "    y = y + edge_size\n",
    "    # Flatten and repeat for each image in the batch\n",
    "    x = x.reshape(-1).repeat(1, num_batch)\n",
    "    y = y.reshape(-1).repeat(1, num_batch)\n",
    "\n",
    "    # Now we want to sample pixels with indicies shifted by disparity in X direction\n",
    "    # For that we convert disparity from % to pixels and add to X indicies\n",
    "    x = x + x_offset.contiguous().view(-1) * width\n",
    "    # Make sure we don't go outside of image\n",
    "    x = torch.clamp(x, 0.0, width - 1 + 2 * edge_size)\n",
    "    # Round disparity to sample from integer-valued pixel grid\n",
    "    y0 = torch.floor(y)\n",
    "    # In X direction round both down and up to apply linear interpolation\n",
    "    # between them later\n",
    "    x0 = torch.floor(x)\n",
    "    x1 = x0 + 1\n",
    "    # After rounding up we might go outside the image boundaries again\n",
    "    x1 = x1.clamp(max=(width - 1 + 2 * edge_size))\n",
    "\n",
    "    # Calculate indices to draw from flattened version of image batch\n",
    "    dim2 = (width + 2 * edge_size)\n",
    "    dim1 = (width + 2 * edge_size) * (height + 2 * edge_size)\n",
    "    # Set offsets for each image in the batch\n",
    "    base = dim1 * torch.arange(num_batch).type(tensor_type).to(torch.device(\"cuda:0\"))\n",
    "    base = base.view(-1, 1).repeat(1, height * width).view(-1)\n",
    "    # One pixel shift in Y  direction equals dim2 shift in flattened array\n",
    "    base_y0 = base + y0 * dim2\n",
    "    # Add two versions of shifts in X direction separately\n",
    "    idx_l = base_y0 + x0\n",
    "    idx_r = base_y0 + x1\n",
    "\n",
    "    # Sample pixels from images\n",
    "    pix_l = im_flat.gather(1, idx_l.repeat(num_channels, 1).long())\n",
    "    pix_r = im_flat.gather(1, idx_r.repeat(num_channels, 1).long())\n",
    "\n",
    "    # Apply linear interpolation to account for fractional offsets\n",
    "    weight_l = x1 - x\n",
    "    weight_r = x - x0\n",
    "    output = weight_l * pix_l + weight_r * pix_r\n",
    "\n",
    "    # Reshape back into image batch and permute back to (N,C,H,W) shape\n",
    "    output = output.view(num_channels, num_batch, height, width).permute(1,0,2,3)\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
